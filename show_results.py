"""
Script simple para mostrar los resultados del benchmark en formato texto
"""
import json
import os

def display_benchmark_results():
    print("ğŸ¯ RESULTADOS DEL BENCHMARK - MICROSERVICIOS")
    print("=" * 60)
    
    # Definir rutas posibles para los resultados
    results_dir = "benchmarks/results"
    possible_files = [
        'benchmark_results.json',  # En directorio actual
        os.path.join(results_dir, 'benchmark_results.json')  # En carpeta results
    ]
    
    # Cargar resultados
    results = None
    loaded_from = None
    
    for file_path in possible_files:
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                results = json.load(f)
            loaded_from = file_path
            break
    
    if not results:
        print("âŒ No se encontrÃ³ el archivo benchmark_results.json en ninguna ubicaciÃ³n")
        return
    
    print(f"ğŸ“ Resultados cargados desde: {loaded_from}")
    
    # Mostrar resultados por servicio
    print("\nğŸ“Š RENDIMIENTO POR SERVICIO:")
    print("-" * 40)
    
    services = {
        'sentiment': 'Sentiment Analyzer',
        'portfolio': 'Portfolio Manager', 
        'garch': 'GARCH Predictor',
        'intraday': 'Intraday Strategy'
    }
    
    for service_key, service_name in services.items():
        if service_key in results and 'avg_time' in results[service_key]:
            data = results[service_key]
            
            print(f"\nğŸ”¹ {service_name.upper()}:")
            print(f"   â±ï¸  Tiempo promedio: {data['avg_time']:.3f}s")
            print(f"   ğŸš€ Throughput est:   {1/data['avg_time']:.2f} req/s")
            print(f"   ğŸ“ˆ Tiempo mÃ­nimo:    {data['min_time']:.3f}s")
            print(f"   ğŸ“‰ Tiempo mÃ¡ximo:    {data['max_time']:.3f}s")
            print(f"   ğŸ“Š DesviaciÃ³n std:   {data['std_time']:.3f}s")
    
    # AnÃ¡lisis de concurrencia
    if 'concurrent' in results:
        concurrent = results['concurrent']
        print(f"\nğŸ”„ PRUEBAS CONCURRENTES:")
        print(f"   âœ… Tasa de Ã©xito: {concurrent['success_rate']*100:.1f}%")
        print(f"   ğŸ“Š Requests totales: {concurrent['total_requests']}")
        print(f"   âœ… Requests exitosos: {concurrent['successful_requests']}")
        print(f"   â±ï¸  Tiempo total: {concurrent['total_time']:.2f}s")
        print(f"   ğŸš€ Throughput: {concurrent['successful_requests']/concurrent['total_time']:.2f} req/s")
    
    # Rankings
    print(f"\nğŸ† RANKINGS:")
    print("-" * 20)
    
    # Servicio mÃ¡s rÃ¡pido
    fastest = min(
        [(name, results[key]['avg_time']) for key, name in services.items() 
         if key in results and 'avg_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸ¥‡ MÃ¡s rÃ¡pido: {fastest[0]} ({fastest[1]:.3f}s)")
    
    # Servicio mÃ¡s lento
    slowest = max(
        [(name, results[key]['avg_time']) for key, name in services.items() 
         if key in results and 'avg_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸŒ MÃ¡s lento: {slowest[0]} ({slowest[1]:.3f}s)")
    
    # MÃ¡s consistente (menor desviaciÃ³n)
    most_consistent = min(
        [(name, results[key]['std_time']) for key, name in services.items() 
         if key in results and 'std_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸ¯ MÃ¡s consistente: {most_consistent[0]} (std: {most_consistent[1]:.3f}s)")
    
    print(f"\nğŸ’¡ RECOMENDACIONES:")
    print(f"   â€¢ Optimizar {slowest[0]} (mayor tiempo de respuesta)")
    print(f"   â€¢ Implementar Ray Remote en servicios computacionalmente intensivos")
    print(f"   â€¢ Considerar cache para reducir latencia")
    
    print(f"\nğŸ“Š GrÃ¡ficas disponibles:")
    
    # Verificar grÃ¡ficas en ambas ubicaciones
    graph_locations = [
        "benchmark_comparison_latest.png",
        os.path.join(results_dir, "benchmark_comparison_latest.png")
    ]
    
    found_graphs = False
    for graph_path in graph_locations:
        if os.path.exists(graph_path):
            print(f"   âœ… {graph_path}")
            found_graphs = True
    
    if not found_graphs:
        print(f"   âŒ No se encontraron grÃ¡ficas")
        print(f"   ğŸ’¡ Ejecuta: python generate_benchmark_charts.py")

if __name__ == "__main__":
    display_benchmark_results()
