"""
Script simple para mostrar los resultados del benchmark en formato texto
"""
import json
import os

def display_benchmark_results():
    print("ğŸ¯ RESULTADOS DEL BENCHMARK - MICROSERVICIOS")
    print("=" * 60)
    
    # Cargar resultados
    if not os.path.exists('benchmark_results.json'):
        print("âŒ No se encontrÃ³ el archivo benchmark_results.json")
        return
    
    with open('benchmark_results.json', 'r') as f:
        results = json.load(f)
    
    # Mostrar resultados por servicio
    print("\nğŸ“Š RENDIMIENTO POR SERVICIO:")
    print("-" * 40)
    
    services = {
        'sentiment': 'Sentiment Analyzer',
        'portfolio': 'Portfolio Manager', 
        'garch': 'GARCH Predictor',
        'intraday': 'Intraday Strategy'
    }
    
    for service_key, service_name in services.items():
        if service_key in results and 'avg_time' in results[service_key]:
            data = results[service_key]
            
            print(f"\nğŸ”¹ {service_name.upper()}:")
            print(f"   â±ï¸  Tiempo promedio: {data['avg_time']:.3f}s")
            print(f"   ğŸš€ Throughput est:   {1/data['avg_time']:.2f} req/s")
            print(f"   ğŸ“ˆ Tiempo mÃ­nimo:    {data['min_time']:.3f}s")
            print(f"   ğŸ“‰ Tiempo mÃ¡ximo:    {data['max_time']:.3f}s")
            print(f"   ğŸ“Š DesviaciÃ³n std:   {data['std_time']:.3f}s")
    
    # AnÃ¡lisis de concurrencia
    if 'concurrent' in results:
        concurrent = results['concurrent']
        print(f"\nğŸ”„ PRUEBAS CONCURRENTES:")
        print(f"   âœ… Tasa de Ã©xito: {concurrent['success_rate']*100:.1f}%")
        print(f"   ğŸ“Š Requests totales: {concurrent['total_requests']}")
        print(f"   âœ… Requests exitosos: {concurrent['successful_requests']}")
        print(f"   â±ï¸  Tiempo total: {concurrent['total_time']:.2f}s")
        print(f"   ğŸš€ Throughput: {concurrent['successful_requests']/concurrent['total_time']:.2f} req/s")
    
    # Rankings
    print(f"\nğŸ† RANKINGS:")
    print("-" * 20)
    
    # Servicio mÃ¡s rÃ¡pido
    fastest = min(
        [(name, results[key]['avg_time']) for key, name in services.items() 
         if key in results and 'avg_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸ¥‡ MÃ¡s rÃ¡pido: {fastest[0]} ({fastest[1]:.3f}s)")
    
    # Servicio mÃ¡s lento
    slowest = max(
        [(name, results[key]['avg_time']) for key, name in services.items() 
         if key in results and 'avg_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸŒ MÃ¡s lento: {slowest[0]} ({slowest[1]:.3f}s)")
    
    # MÃ¡s consistente (menor desviaciÃ³n)
    most_consistent = min(
        [(name, results[key]['std_time']) for key, name in services.items() 
         if key in results and 'std_time' in results[key]], 
        key=lambda x: x[1]
    )
    print(f"ğŸ¯ MÃ¡s consistente: {most_consistent[0]} (std: {most_consistent[1]:.3f}s)")
    
    print(f"\nğŸ’¡ RECOMENDACIONES:")
    print(f"   â€¢ Optimizar {slowest[0]} (mayor tiempo de respuesta)")
    print(f"   â€¢ Implementar Ray Remote en servicios computacionalmente intensivos")
    print(f"   â€¢ Considerar cache para reducir latencia")
    
    print(f"\nğŸ“Š GrÃ¡ficas disponibles:")
    if os.path.exists('benchmark_comparison_latest.png'):
        print(f"   âœ… benchmark_comparison_latest.png")
    else:
        print(f"   âŒ No se encontraron grÃ¡ficas")

if __name__ == "__main__":
    display_benchmark_results()
