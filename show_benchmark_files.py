"""
Script para mostrar resumen de archivos de benchmark organizados
"""
import os
from datetime import datetime

def show_benchmark_files():
    print("ğŸ“ ARCHIVOS DE BENCHMARK ORGANIZADOS")
    print("=" * 50)
    
    results_dir = "benchmarks/results"
    
    if not os.path.exists(results_dir):
        print(f"âŒ Directorio {results_dir} no encontrado")
        return
    
    files = os.listdir(results_dir)
    files.sort()
    
    # Categorizar archivos
    json_files = [f for f in files if f.endswith('.json')]
    png_files = [f for f in files if f.endswith('.png')]
    txt_files = [f for f in files if f.endswith('.txt')]
    md_files = [f for f in files if f.endswith('.md')]
    
    print(f"\nğŸ“Š DATOS DE BENCHMARK ({len(json_files)} archivos):")
    for file in json_files:
        file_path = os.path.join(results_dir, file)
        size = os.path.getsize(file_path)
        mod_time = os.path.getmtime(file_path)
        mod_time_str = datetime.fromtimestamp(mod_time).strftime("%Y-%m-%d %H:%M:%S")
        print(f"   ğŸ“„ {file} ({size:,} bytes) - {mod_time_str}")
    
    print(f"\nğŸ“ˆ GRÃFICAS ({len(png_files)} archivos):")
    for file in png_files:
        file_path = os.path.join(results_dir, file)
        size = os.path.getsize(file_path)
        mod_time = os.path.getmtime(file_path)
        mod_time_str = datetime.fromtimestamp(mod_time).strftime("%Y-%m-%d %H:%M:%S")
        
        if "comparison" in file:
            icon = "ğŸ”„"
            desc = "ComparaciÃ³n secuencial vs Ray"
        elif "detailed" in file:
            icon = "ğŸ“Š"
            desc = "MÃ©tricas detalladas"
        elif "latest" in file:
            icon = "ğŸ†•"
            desc = "Ãšltima comparaciÃ³n generada"
        else:
            icon = "ğŸ“ˆ"
            desc = "GrÃ¡fica de benchmark"
            
        print(f"   {icon} {file} ({size:,} bytes) - {desc}")
        print(f"      ğŸ“… {mod_time_str}")
    
    print(f"\nğŸ“ REPORTES ({len(txt_files)} archivos):")
    for file in txt_files:
        file_path = os.path.join(results_dir, file)
        size = os.path.getsize(file_path)
        mod_time = os.path.getmtime(file_path)
        mod_time_str = datetime.fromtimestamp(mod_time).strftime("%Y-%m-%d %H:%M:%S")
        print(f"   ğŸ“„ {file} ({size:,} bytes) - {mod_time_str}")
    
    print(f"\nğŸ“‹ DOCUMENTACIÃ“N ({len(md_files)} archivos):")
    for file in md_files:
        file_path = os.path.join(results_dir, file)
        size = os.path.getsize(file_path)
        mod_time = os.path.getmtime(file_path)
        mod_time_str = datetime.fromtimestamp(mod_time).strftime("%Y-%m-%d %H:%M:%S")
        print(f"   ğŸ“– {file} ({size:,} bytes) - {mod_time_str}")
    
    # Mostrar estructura recomendada
    print(f"\nğŸ—‚ï¸  ESTRUCTURA ORGANIZADA:")
    print(f"   ğŸ“ benchmarks/")
    print(f"   â”œâ”€â”€ ğŸ“ results/")
    print(f"   â”‚   â”œâ”€â”€ ğŸ“„ benchmark_results.json (datos originales)")
    print(f"   â”‚   â”œâ”€â”€ ğŸ“„ ray_benchmark_results.json (datos Ray - pendiente)")
    print(f"   â”‚   â”œâ”€â”€ ğŸ“ˆ benchmark_comparison_latest.png (grÃ¡fica principal)")
    print(f"   â”‚   â”œâ”€â”€ ğŸ“Š detailed_metrics_*.png (mÃ©tricas detalladas)")
    print(f"   â”‚   â”œâ”€â”€ ğŸ“ benchmark_report_*.txt (reportes)")
    print(f"   â”‚   â””â”€â”€ ğŸ“– REPORTE_FINAL_PROYECTO.md (documentaciÃ³n)")
    print(f"   â”œâ”€â”€ ğŸ“ scripts/")
    print(f"   â”‚   â”œâ”€â”€ ğŸ benchmark_original.py")
    print(f"   â”‚   â”œâ”€â”€ ğŸ ray_comparison_benchmark.py")
    print(f"   â”‚   â””â”€â”€ ğŸ otros scripts...")
    print(f"   â””â”€â”€ ğŸ“„ requirements.txt")
    
    print(f"\nğŸ¯ ARCHIVOS PRINCIPALES PARA REPORTE:")
    print(f"   ğŸ“Š {results_dir}/benchmark_comparison_latest.png")
    print(f"   ğŸ“„ {results_dir}/benchmark_results.json")
    print(f"   ğŸ“– {results_dir}/REPORTE_FINAL_PROYECTO.md")
    
    print(f"\nğŸ’¡ COMANDOS ÃšTILES:")
    print(f"   ğŸ“Š Ver resultados: python show_results.py")
    print(f"   ğŸ“ˆ Generar grÃ¡ficas: python generate_benchmark_charts.py")
    print(f"   ğŸ”„ Ejecutar benchmark: python benchmarks/scripts/benchmark_original.py")

if __name__ == "__main__":
    show_benchmark_files()
